{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Modeling of Financial Data with Matrix Product States\n",
    "This notebook applies the MPS training method from the paper \"Unsupervised Generative Modeling Using Matrix Product States\" to a financial dataset.\n",
    "\n",
    "\n",
    "<ins>Unsupervised Generative Modeling Using Matrix Product States </ins>\\\n",
    "Zhao-Yu Han, Jun Wang, Heng Fan, Lei Wang, and Pan Zhang \\\n",
    "Phys. Rev. X 8, 031012 â€“ Published 17 July 2018 \\\n",
    "[https://doi.org/10.1103/PhysRevX.8.031012](https://doi.org/10.1103/PhysRevX.8.031012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /workspaces/quantum-research/\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "plt.style.use(['science','ieee','no-latex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/currencies.parquet')\n",
    "print(df.head())\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "df['JPYUSD'].plot(ax=ax[0])\n",
    "df.drop(columns='JPYUSD').plot(ax=ax[1])\n",
    "ax[0].set_title('JPYUSD')\n",
    "ax[1].set_title('Other currencies')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains the daily mid price $P_i$ of each of the four currency pairs.\n",
    "\n",
    "1. Compute Log Returns: $L_i = log(\\frac{P_{i+1}-P_i}{P_i}+1)$\n",
    "\n",
    "2. Apply Standard Scaler: $S_i = \\frac{L_i - \\mu_L}{\\sigma_L}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[[\"EURUSD\", \"GBPUSD\"]]  # uncomment to use only EURUSD and GBPUSD -> faster computation\n",
    "num_features = len(df.columns)\n",
    "\n",
    "# Check for nan values\n",
    "print(\"NaN values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Compute Log returns\n",
    "df = np.log(df.pct_change() + 1) \n",
    "df.dropna(inplace=True)  # Drop NaN from the first row\n",
    "\n",
    "# Apply standard scaler\n",
    "df = (df - df.mean()) / df.std()\n",
    "\n",
    "# plot\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histograms\n",
    "df.hist(bins=1000, figsize=(10, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mps.utils import real_to_binary\n",
    "\n",
    "# Convert real values to binary\n",
    "bits_per_feature = 4\n",
    "df_binary, conv_min_max = real_to_binary(df.values, bits_per_feature)\n",
    "print(\"Shape of the binary dataframe:\", df_binary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of the dataset:\", len(df_binary))\n",
    "unique_samples = np.unique(df_binary, axis=0)\n",
    "print(\"Number of unique samples:\", len(unique_samples))\n",
    "\n",
    "# Compute probability of each unique sample\n",
    "prob = np.zeros(len(unique_samples))\n",
    "for i, sample in enumerate(unique_samples):\n",
    "    prob[i] = np.sum(np.all(df_binary == sample, axis=1)) / len(df_binary)\n",
    "\n",
    "# Compute shannon entropy\n",
    "shannon_entropy = -np.sum(prob * np.log2(prob))\n",
    "print(\"Shannon entropy of the dataset:\", shannon_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mps.utils import sample_info, array_to_str\n",
    "\n",
    "def get_features_for_quasi_dist(samples_dict, bits_per_feature, num_features):\n",
    "    sample_gen_arr, sample_gen_probs = sample_info(samples_dict)\n",
    "    res_dicts = []\n",
    "    for i in range(num_features):\n",
    "        f_arr = array_to_str(sample_gen_arr[:,i*bits_per_feature:(i+1)*bits_per_feature]).tolist()\n",
    "        f_dict = dict()\n",
    "        for j in range(len(f_arr)):\n",
    "            if f_arr[j] in f_dict:\n",
    "                f_dict[f_arr[j]] += sample_gen_probs[j]\n",
    "            else:\n",
    "                f_dict[f_arr[j]] = sample_gen_probs[j]\n",
    "        assert round(sum([v for v in f_dict.values()]), 12) == 1.0\n",
    "        res_dicts.append(f_dict)\n",
    "\n",
    "    return res_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from qiskit.visualization import plot_histogram\n",
    "\n",
    "target_str = array_to_str(df_binary)\n",
    "target_dict = Counter(target_str)\n",
    "bin_feat_dicts = get_features_for_quasi_dist(target_dict, bits_per_feature, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for i, binary_feature in enumerate(bin_feat_dicts):\n",
    "    fig = plot_histogram(binary_feature, figsize=(10, 3), title=df.columns[i], bar_labels=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mps.mps import MPS\n",
    "\n",
    "m = MPS(bits_per_feature * df.shape[1])\n",
    "m.left_cano()\n",
    "m.designate_data(df_binary)\n",
    "m.init_cumulants()\n",
    "\n",
    "m.cutoff = 5e-5\n",
    "m.descent_step_length = 0.05\n",
    "m.descent_steps = 10\n",
    "m.train(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Negative Log Likelihood (NLL) Loss Function\n",
    "- $|\\mathcal{T}|$: Size of training set\n",
    "- $\\nu$: Binary Sample from MPS\n",
    "\n",
    "$$\\mathcal{L} = - \\frac{1}{|\\mathcal{T}|} \\sum_{\\nu \\in \\mathcal{T}} ln(\\mathbb{P}(\\nu))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = np.array(m.Loss)\n",
    "plt.plot(loss)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 100 samples from the trained MPS\n",
    "samples_gen = np.full((1000, df_binary.shape[1]), np.nan)\n",
    "for i in range(1000):\n",
    "    samples_gen[i] = m.generate_sample_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histograms against target\n",
    "generated_str = array_to_str(samples_gen)\n",
    "generated_dict = Counter(generated_str)\n",
    "gen_samples_dicts = get_features_for_quasi_dist(generated_dict, bits_per_feature, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for i, generated_feature in enumerate(gen_samples_dicts):\n",
    "    fig = plot_histogram([bin_feat_dicts[i], generated_feature], figsize=(10, 3), title=df.columns[i], bar_labels=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
